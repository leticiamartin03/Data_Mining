{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 08: Data streams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Leticia Martin Cabrera</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">leticia.martin03@estudiant.upf.edu</font>\n",
    "\n",
    "Date: <font color=\"blue\">20/11/2021</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nltk\n",
    "import gzip\n",
    "import random\n",
    "import statistics\n",
    "import secrets\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset and how to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "INPUT_FILE = \"DCEP-reports-en.txt.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Producer in Python that reads a filename by words\n",
    "def read_by_words(filename, max_words=-1, report_every=-1):\n",
    "    \n",
    "    # Open the input file\n",
    "    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
    "        \n",
    "        # Initialize counter of words to stop at max_words\n",
    "        counter = 0\n",
    "    \n",
    "        # Regular expression to identify words having 4 letters or more and beginning with a-z\n",
    "        word_expr = re.compile('^[a-z][a-z0-9]{4,}$', re.IGNORECASE)\n",
    "\n",
    "        # Iterate through lines in the file\n",
    "        for line in file:\n",
    "            \n",
    "            if counter > max_words and max_words != -1:\n",
    "                break\n",
    "                \n",
    "            for word in nltk.word_tokenize(line):\n",
    "                if word_expr.match(word):\n",
    "                    counter += 1\n",
    "                    \n",
    "                    # Report\n",
    "                    if (report_every != -1) and (counter % report_every == 0):\n",
    "                        if max_words == -1:\n",
    "                            print(\"- Read %d words so far\" % (counter))\n",
    "                        else:\n",
    "                            print(\"- Read %d/%d words so far\" % (counter, max_words))\n",
    "\n",
    "                    # Produce the word\n",
    "                    yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current word 'implemented'\n",
      "Current word 'difficulties'\n",
      "Current word 'research'\n",
      "Current word 'States'\n",
      "Current word 'producers'\n",
      "Current word 'opinion'\n",
      "Current word 'funds'\n",
      "Current word 'approach'\n",
      "- Read 100000/300000 words so far\n",
      "Current word 'allergies'\n",
      "Current word 'sixth'\n",
      "Current word 'study'\n",
      "Current word 'Rights'\n",
      "Current word 'concerned'\n",
      "Current word 'announced'\n",
      "Current word 'respect'\n",
      "Current word 'available'\n",
      "Current word 'ability'\n",
      "Current word 'Union'\n",
      "Current word 'Members'\n",
      "Current word 'Total'\n",
      "Current word 'films'\n",
      "Current word 'awareness'\n",
      "- Read 200000/300000 words so far\n",
      "Current word 'determine'\n",
      "Current word 'poverty'\n",
      "Current word 'gender'\n",
      "Current word 'recourse'\n",
      "Current word 'products'\n",
      "Current word 'deposit'\n",
      "Current word 'guidelines'\n",
      "Current word 'shall'\n",
      "Current word 'necessary'\n",
      "Current word 'instrument'\n",
      "Current word 'Commission'\n",
      "Current word 'comitology'\n",
      "Current word 'together'\n",
      "- Read 300000/300000 words so far\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Iterate through the file\n",
    "for word in read_by_words(INPUT_FILE, max_words=300000, report_every=100000):\n",
    "    # Prints 0.005% of words\n",
    "    if random.random() < 0.0001:\n",
    "        print(\"Current word '%s'\" % (word)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Determine approximately the top-5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing function add_to_reservoir  that adds an item to the reservoir, maintaining its size\n",
    "def add_to_reservoir(reservoir, item, max_reservoir_size):\n",
    "    \n",
    "    #Checking if reservoir is full\n",
    "    if len(reservoir) >= max_reservoir_size:\n",
    "        \n",
    "        #Discard random elemnt and insert the new item in the same position \n",
    "        random_pos = random.randint(0,max_reservoir_size-1)\n",
    "        reservoir[random_pos]  = item\n",
    "        \n",
    "    #Adding new item without deleting any element    \n",
    "    else:\n",
    "        reservoir.append(item)\n",
    "        \n",
    "    assert(len(reservoir) <= max_reservoir_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating reservoir_sampling funtion that iterates through the file using the reservoir sampling method\n",
    "def reservoir_sampling(filename, reservoir_size, max_words=-1, report_every=-1):\n",
    "    reservoir = []\n",
    "\n",
    "    words_read = 0  #word counter\n",
    "\n",
    "    for word in read_by_words(filename, max_words=max_words, report_every=report_every):\n",
    "        \n",
    "        words_read += 1 #increases the word counter\n",
    "\n",
    "        #Checking if reservoir is full\n",
    "        if words_read >= reservoir_size:\n",
    "            random_element = random.random()\n",
    "            \n",
    "            \n",
    "            #checking if the new element arrives with problability s/n (reservoir_size/words_read)\n",
    "            if random_element <= reservoir_size/words_read:\n",
    "                \n",
    "                #inserting the new word into reservoir\n",
    "                add_to_reservoir(reservoir, word, reservoir_size)\n",
    "                \n",
    "        #Adding new word without deleting any word       \n",
    "        else: \n",
    "            add_to_reservoir(reservoir, word, reservoir_size)\n",
    "            \n",
    "\n",
    "    return (words_read, reservoir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "Number of items seen    : 300007\n",
      "Number of items sampled : 500\n"
     ]
    }
   ],
   "source": [
    "# Testing the function reservoir_sampling\n",
    "\n",
    "reservoir_size = 500\n",
    "(items_seen, reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=300000, report_every=100000)\n",
    "\n",
    "print(\"Number of items seen    : %d\" % items_seen)\n",
    "print(\"Number of items sampled : %d\" % len(reservoir) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Article\n",
      "7 Parliament\n",
      "7 European\n",
      "7 Amendment\n",
      "6 their\n",
      "5 which\n",
      "5 shall\n",
      "4 including\n",
      "4 development\n",
      "4 States\n"
     ]
    }
   ],
   "source": [
    "#compute the absolute frequencies of the top 5\n",
    "\n",
    "freq = {}\n",
    "for item in reservoir:\n",
    "    freq[item] = reservoir.count(item)\n",
    "\n",
    "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:10]\n",
    "for absolute_frequency, word in most_frequent_items:\n",
    "    print(\"%d %s\" % (absolute_frequency, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018 Article\n",
      "0.014 Parliament\n",
      "0.014 European\n",
      "0.014 Amendment\n",
      "0.012 their\n",
      "0.010 which\n",
      "0.010 shall\n",
      "0.008 including\n",
      "0.008 development\n",
      "0.008 States\n"
     ]
    }
   ],
   "source": [
    "#print the top items and their relative frequencies\n",
    "freq = {}\n",
    "for item in reservoir:\n",
    "    freq[item] = reservoir.count(item)/len(reservoir)\n",
    "\n",
    "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:10]\n",
    "for relative_frequency, word in most_frequent_items:\n",
    "    print(\"%.3f %s\" % (relative_frequency, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### Reservoir size 100 ###############\n",
      "- Read 250000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 750000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "terms --> Absolute frequency: 20000 |Relative frequency: 0.0200\n",
      "rights --> Absolute frequency: 20000 |Relative frequency: 0.0200\n",
      "Parliament --> Absolute frequency: 20000 |Relative frequency: 0.0200\n",
      "would --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "workers --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "\n",
      "############### Reservoir size 500 ###############\n",
      "- Read 250000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 750000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "information --> Absolute frequency: 12000 |Relative frequency: 0.0120\n",
      "Commission --> Absolute frequency: 12000 |Relative frequency: 0.0120\n",
      "which --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "protection --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "national --> Absolute frequency: 8000 |Relative frequency: 0.0080\n",
      "\n",
      "############### Reservoir size 1000 ###############\n",
      "- Read 250000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 750000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "Commission --> Absolute frequency: 14000 |Relative frequency: 0.0140\n",
      "should --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "which --> Absolute frequency: 9000 |Relative frequency: 0.0090\n",
      "shall --> Absolute frequency: 9000 |Relative frequency: 0.0090\n",
      "Council --> Absolute frequency: 8000 |Relative frequency: 0.0080\n",
      "\n",
      "############### Reservoir size 3000 ###############\n",
      "- Read 250000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 750000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "European --> Absolute frequency: 12000 |Relative frequency: 0.0120\n",
      "Commission --> Absolute frequency: 10000 |Relative frequency: 0.0100\n",
      "Member --> Absolute frequency: 7666 |Relative frequency: 0.0077\n",
      "Article --> Absolute frequency: 7000 |Relative frequency: 0.0070\n",
      "which --> Absolute frequency: 6666 |Relative frequency: 0.0067\n",
      "\n",
      "############### Reservoir size 5000 ###############\n",
      "- Read 250000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 750000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "European --> Absolute frequency: 12400 |Relative frequency: 0.0124\n",
      "Article --> Absolute frequency: 9600 |Relative frequency: 0.0096\n",
      "which --> Absolute frequency: 8600 |Relative frequency: 0.0086\n",
      "should --> Absolute frequency: 8600 |Relative frequency: 0.0086\n",
      "Member --> Absolute frequency: 8200 |Relative frequency: 0.0082\n"
     ]
    }
   ],
   "source": [
    "#Print the relative and absolute frequency of the words increasing the max limit of words\n",
    "\n",
    "#Reservoir sizes\n",
    "sizes = [100,500,1000,3000,5000]\n",
    "\n",
    "for size in sizes:\n",
    "    print(\"\\n############### Reservoir size %d ###############\" %size)\n",
    "    \n",
    "    #Fixing max limit of words at one million\n",
    "    (items_seen, reservoir) = reservoir_sampling(INPUT_FILE, size, max_words=1000000, report_every=250000)\n",
    "    \n",
    "    #Compute absolute and relatives frequencies\n",
    "    freq = {}\n",
    "    for item in reservoir:\n",
    "        freq[item] = reservoir.count(item)\n",
    "\n",
    "    most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "    \n",
    "    #printing the results \n",
    "    for absolute_frequency, word in most_frequent_items:\n",
    "        print(\"%s --> Absolute frequency: %d |Relative frequency: %.4f\" % (word, absolute_frequency*items_seen/len(reservoir), absolute_frequency/len(reservoir)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not obtained stable results with any of the reservoir size we have tested. We can see that at best only one word in the top 3 matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### Reservoir size 100 ###############\n",
      "Justification --> Absolute frequency: 308470 |Relative frequency: 0.0300\n",
      "which --> Absolute frequency: 205647 |Relative frequency: 0.0200\n",
      "their --> Absolute frequency: 205647 |Relative frequency: 0.0200\n",
      "strategy --> Absolute frequency: 205647 |Relative frequency: 0.0200\n",
      "regional --> Absolute frequency: 205647 |Relative frequency: 0.0200\n",
      "\n",
      "############### Reservoir size 500 ###############\n",
      "should --> Absolute frequency: 143952 |Relative frequency: 0.0140\n",
      "Commission --> Absolute frequency: 143952 |Relative frequency: 0.0140\n",
      "shall --> Absolute frequency: 123388 |Relative frequency: 0.0120\n",
      "Amendment --> Absolute frequency: 123388 |Relative frequency: 0.0120\n",
      "proposed --> Absolute frequency: 102823 |Relative frequency: 0.0100\n",
      "\n",
      "############### Reservoir size 1000 ###############\n",
      "European --> Absolute frequency: 133670 |Relative frequency: 0.0130\n",
      "Member --> Absolute frequency: 123388 |Relative frequency: 0.0120\n",
      "Commission --> Absolute frequency: 123388 |Relative frequency: 0.0120\n",
      "Article --> Absolute frequency: 123388 |Relative frequency: 0.0120\n",
      "shall --> Absolute frequency: 102823 |Relative frequency: 0.0100\n",
      "\n",
      "############### Reservoir size 3000 ###############\n",
      "Member --> Absolute frequency: 126815 |Relative frequency: 0.0123\n",
      "Commission --> Absolute frequency: 126815 |Relative frequency: 0.0123\n",
      "which --> Absolute frequency: 92541 |Relative frequency: 0.0090\n",
      "should --> Absolute frequency: 92541 |Relative frequency: 0.0090\n",
      "European --> Absolute frequency: 89113 |Relative frequency: 0.0087\n",
      "\n",
      "############### Reservoir size 5000 ###############\n",
      "Commission --> Absolute frequency: 137783 |Relative frequency: 0.0134\n",
      "European --> Absolute frequency: 121331 |Relative frequency: 0.0118\n",
      "Article --> Absolute frequency: 111049 |Relative frequency: 0.0108\n",
      "Amendment --> Absolute frequency: 92541 |Relative frequency: 0.0090\n",
      "States --> Absolute frequency: 90484 |Relative frequency: 0.0088\n"
     ]
    }
   ],
   "source": [
    "#Print the relative and absolute frequency of the words without max limit of words\n",
    "\n",
    "#Reservoir sizes\n",
    "sizes = [100,500,1000,3000,5000]\n",
    "\n",
    "for size in sizes:\n",
    "    print(\"\\n############### Reservoir size %d ###############\" %size)\n",
    "    \n",
    "    #Computing reservoir sampling algortihm without max limit of words\n",
    "    (items_seen, reservoir) = reservoir_sampling(INPUT_FILE, size)\n",
    "    \n",
    "    #Compute absolute and relatives frequencies\n",
    "    freq = {}\n",
    "    for item in reservoir:\n",
    "        freq[item] = reservoir.count(item)\n",
    "\n",
    "    most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "    \n",
    "    #printing the results\n",
    "    for absolute_frequency, word in most_frequent_items:\n",
    "        print(\"%s --> Absolute frequency: %d |Relative frequency: %.4f\" % (word, absolute_frequency*items_seen/len(reservoir), absolute_frequency/len(reservoir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that if we increase the size of reservoir there are more words matches. Commission and European are the most frequent words. However, we can not conclude that  assure the stability of the output. I think that we should choose a higher size but the inconvenience of this is that the code take more time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determine approximately the distinct number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def count_trailing_zeroes(number):\n",
    "    count = 0\n",
    "    while number & 1 == 0:\n",
    "        count += 1\n",
    "        number = number >> 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def random_hash_function():\n",
    "    # We use a cryptographically safe generator for the salt of our hash function\n",
    "    salt = secrets.token_bytes(32)\n",
    "    return lambda string: hash(string + str(salt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test 1\n",
      "Estimate on pass 1: 2048 distinct words\n",
      "Estimate on pass 2: 16384 distinct words\n",
      "Estimate on pass 3: 8192 distinct words\n",
      "Estimate on pass 4: 2048 distinct words\n",
      "Estimate on pass 5: 1024 distinct words\n",
      "Estimate on pass 6: 16384 distinct words\n",
      "Estimate on pass 7: 2048 distinct words\n",
      "Estimate on pass 8: 2048 distinct words\n",
      "Estimate on pass 9: 16384 distinct words\n",
      "Estimate on pass 10: 2048 distinct words\n",
      "\n",
      " Test 2\n",
      "Estimate on pass 1: 2048 distinct words\n",
      "Estimate on pass 2: 4096 distinct words\n",
      "Estimate on pass 3: 4096 distinct words\n",
      "Estimate on pass 4: 1024 distinct words\n",
      "Estimate on pass 5: 4096 distinct words\n",
      "Estimate on pass 6: 4096 distinct words\n",
      "Estimate on pass 7: 8192 distinct words\n",
      "Estimate on pass 8: 8192 distinct words\n",
      "Estimate on pass 9: 1024 distinct words\n",
      "Estimate on pass 10: 2048 distinct words\n",
      "\n",
      " Test 3\n",
      "Estimate on pass 1: 1024 distinct words\n",
      "Estimate on pass 2: 4096 distinct words\n",
      "Estimate on pass 3: 8192 distinct words\n",
      "Estimate on pass 4: 2048 distinct words\n",
      "Estimate on pass 5: 4096 distinct words\n",
      "Estimate on pass 6: 4096 distinct words\n",
      "Estimate on pass 7: 8192 distinct words\n",
      "Estimate on pass 8: 8192 distinct words\n",
      "Estimate on pass 9: 1024 distinct words\n",
      "Estimate on pass 10: 2048 distinct words\n"
     ]
    }
   ],
   "source": [
    "#Estimating the number of distinc words using Flajolet-Martin probabilistic counting method\n",
    "number_of_passes = 10\n",
    "all_estimates = []\n",
    "\n",
    "#Executing 3 times the algorithm \n",
    "for i in range(3):\n",
    "    estimates = []\n",
    "    print(\"\\n Test %d\" % (i+1))\n",
    "    for i in range(number_of_passes):\n",
    "        # read the file and generate an estimate\n",
    "        R = 0\n",
    "\n",
    "        #Create hash funcion h\n",
    "        h = random_hash_function()\n",
    "\n",
    "        #reading the entire file\n",
    "        for word in read_by_words(INPUT_FILE, max_words = 30000):\n",
    "\n",
    "            #Compute hash value \n",
    "            hash_value = h(word)\n",
    "\n",
    "            #calculate the number of trailing zeroes in h(u)\n",
    "            trailing_zeros = count_trailing_zeroes(hash_value)\n",
    "\n",
    "            #Maintain R as the maximum value of trailing_zeros seen so far\n",
    "            if trailing_zeros > R:\n",
    "                R = trailing_zeros\n",
    "\n",
    "        #Add 2^R as an estimate for the number of distinct words seen       \n",
    "        estimate = 2**R\n",
    "        estimates.append(estimate)\n",
    "\n",
    "        print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))\n",
    "    all_estimates.append(estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1\n",
      "* Average of estimate: 6860.8\n",
      "* Median  of estimates: 2048.0\n",
      "TEST 2\n",
      "* Average of estimate: 3891.2\n",
      "* Median  of estimates: 4096.0\n",
      "TEST 3\n",
      "* Average of estimate: 4300.8\n",
      "* Median  of estimates: 4096.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the median of estimates obtained in 3 separate runs \n",
    "for i,estimates in enumerate(all_estimates):\n",
    "    print(\"TEST %d\"% (i+1))\n",
    "    print(\"* Average of estimate: %.1f\" % (statistics.mean(estimates)))\n",
    "    print(\"* Median  of estimates: %.1f\" % (statistics.median(estimates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test 1\n",
      "Estimate on pass 1: 16384 distinct words\n",
      "Estimate on pass 2: 4096 distinct words\n",
      "Estimate on pass 3: 4096 distinct words\n",
      "Estimate on pass 4: 32768 distinct words\n",
      "Estimate on pass 5: 4096 distinct words\n",
      "Estimate on pass 6: 4096 distinct words\n",
      "Estimate on pass 7: 4096 distinct words\n",
      "Estimate on pass 8: 2048 distinct words\n",
      "Estimate on pass 9: 262144 distinct words\n",
      "Estimate on pass 10: 4096 distinct words\n",
      "Estimate on pass 11: 4096 distinct words\n",
      "Estimate on pass 12: 4096 distinct words\n",
      "Estimate on pass 13: 8192 distinct words\n",
      "Estimate on pass 14: 4096 distinct words\n",
      "Estimate on pass 15: 16384 distinct words\n",
      "Estimate on pass 16: 1024 distinct words\n",
      "Estimate on pass 17: 4096 distinct words\n",
      "Estimate on pass 18: 4096 distinct words\n",
      "Estimate on pass 19: 4096 distinct words\n",
      "Estimate on pass 20: 16384 distinct words\n",
      "\n",
      " Test 2\n",
      "Estimate on pass 1: 2048 distinct words\n",
      "Estimate on pass 2: 4096 distinct words\n",
      "Estimate on pass 3: 2048 distinct words\n",
      "Estimate on pass 4: 512 distinct words\n",
      "Estimate on pass 5: 32768 distinct words\n",
      "Estimate on pass 6: 2048 distinct words\n",
      "Estimate on pass 7: 1024 distinct words\n",
      "Estimate on pass 8: 4096 distinct words\n",
      "Estimate on pass 9: 4096 distinct words\n",
      "Estimate on pass 10: 2048 distinct words\n",
      "Estimate on pass 11: 32768 distinct words\n",
      "Estimate on pass 12: 4096 distinct words\n",
      "Estimate on pass 13: 2048 distinct words\n",
      "Estimate on pass 14: 512 distinct words\n",
      "Estimate on pass 15: 524288 distinct words\n",
      "Estimate on pass 16: 8192 distinct words\n",
      "Estimate on pass 17: 16384 distinct words\n",
      "Estimate on pass 18: 4096 distinct words\n",
      "Estimate on pass 19: 16384 distinct words\n",
      "Estimate on pass 20: 4096 distinct words\n",
      "\n",
      " Test 3\n",
      "Estimate on pass 1: 4096 distinct words\n",
      "Estimate on pass 2: 16384 distinct words\n",
      "Estimate on pass 3: 8192 distinct words\n",
      "Estimate on pass 4: 2048 distinct words\n",
      "Estimate on pass 5: 65536 distinct words\n",
      "Estimate on pass 6: 131072 distinct words\n",
      "Estimate on pass 7: 2048 distinct words\n",
      "Estimate on pass 8: 8192 distinct words\n",
      "Estimate on pass 9: 65536 distinct words\n",
      "Estimate on pass 10: 4096 distinct words\n",
      "Estimate on pass 11: 2048 distinct words\n",
      "Estimate on pass 12: 4096 distinct words\n",
      "Estimate on pass 13: 8192 distinct words\n",
      "Estimate on pass 14: 4096 distinct words\n",
      "Estimate on pass 15: 16384 distinct words\n",
      "Estimate on pass 16: 8192 distinct words\n",
      "Estimate on pass 17: 1024 distinct words\n",
      "Estimate on pass 18: 2048 distinct words\n",
      "Estimate on pass 19: 2048 distinct words\n",
      "Estimate on pass 20: 16384 distinct words\n"
     ]
    }
   ],
   "source": [
    "#Estimating the number of distinc words using Flajolet-Martin probabilistic counting method\n",
    "#Increase the number of passes\n",
    "number_of_passes = 20\n",
    "all_estimates = []\n",
    "\n",
    "#Executing 3 times the algorithm \n",
    "for i in range(3):\n",
    "    estimates = []\n",
    "    print(\"\\n Test %d\" % (i+1))\n",
    "    for i in range(number_of_passes):\n",
    "        # read the file and generate an estimate\n",
    "        R = 0\n",
    "\n",
    "        #Create hash funcion h\n",
    "        h = random_hash_function()\n",
    "\n",
    "        #reading the entire file\n",
    "        for word in read_by_words(INPUT_FILE, max_words = 30000):\n",
    "\n",
    "            #Compute hash value \n",
    "            hash_value = h(word)\n",
    "\n",
    "            #calculate the number of trailing zeroes in h(u)\n",
    "            trailing_zeros = count_trailing_zeroes(hash_value)\n",
    "\n",
    "            #Maintain R as the maximum value of trailing_zeros seen so far\n",
    "            if trailing_zeros > R:\n",
    "                R = trailing_zeros\n",
    "\n",
    "        #Add 2^R as an estimate for the number of distinct words seen       \n",
    "        estimate = 2**R\n",
    "        estimates.append(estimate)\n",
    "\n",
    "        print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))\n",
    "    all_estimates.append(estimates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1\n",
      "* Average of estimate: 20224.0\n",
      "* Median  of estimates: 4096.0\n",
      "TEST 2\n",
      "* Average of estimate: 33382.4\n",
      "* Median  of estimates: 4096.0\n",
      "TEST 3\n",
      "* Average of estimate: 18585.6\n",
      "* Median  of estimates: 6144.0\n"
     ]
    }
   ],
   "source": [
    "## Compute the median of estimates obtained in 3 separate runs \n",
    "for i,estimates in enumerate(all_estimates):\n",
    "    print(\"TEST %d\"% (i+1))\n",
    "    print(\"* Average of estimate: %.1f\" % (statistics.mean(estimates)))\n",
    "    print(\"* Median  of estimates: %.1f\" % (statistics.median(estimates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Remove the limit of max words, or set to a high number, but notice that you do no need to use more than one hour of computer processing time, and perform the 10 passes. Replace this cell with the results you obtained in each pass, and whether the average or the median seem more appropriate for this probabilistic counting.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate on pass 1: 65536 distinct words\n",
      "Estimate on pass 2: 32768 distinct words\n",
      "Estimate on pass 3: 65536 distinct words\n",
      "Estimate on pass 4: 65536 distinct words\n",
      "Estimate on pass 5: 65536 distinct words\n",
      "Estimate on pass 6: 16384 distinct words\n",
      "Estimate on pass 7: 32768 distinct words\n",
      "Estimate on pass 8: 65536 distinct words\n",
      "Estimate on pass 9: 16384 distinct words\n",
      "Estimate on pass 10: 65536 distinct words\n"
     ]
    }
   ],
   "source": [
    "#Estimating the number of distinc words using Flajolet-Martin probabilistic counting method removing the limit of max words.\n",
    "\n",
    "number_of_passes = 10\n",
    "estimates = []\n",
    "\n",
    "for i in range(number_of_passes):\n",
    "    #read the file and generate an estimate\n",
    "    R = 0\n",
    "\n",
    "    #Create hash funcion h\n",
    "    h = random_hash_function()\n",
    "\n",
    "    #reading the entire file\n",
    "    for word in read_by_words(INPUT_FILE):\n",
    "\n",
    "        #Compute hash value \n",
    "        hash_value = h(word)\n",
    "\n",
    "        #calculate the number of trailing zeroes in h(u)\n",
    "        trailing_zeros = count_trailing_zeroes(hash_value)\n",
    "\n",
    "        #Maintain R as the maximum value of trailing_zeros seen so far\n",
    "        if trailing_zeros > R:\n",
    "            R = trailing_zeros\n",
    "\n",
    "    #Add 2^R as an estimate for the number of distinct words seen       \n",
    "    estimate = 2**R\n",
    "    estimates.append(estimate)\n",
    "\n",
    "    print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average of estimates: 18585.6\n",
      "* Median  of estimates: 6144.0\n"
     ]
    }
   ],
   "source": [
    "#Compute the average and median\n",
    "print(\"* Average of estimates: %.1f\" % (statistics.mean(estimates)))\n",
    "print(\"* Median  of estimates: %.1f\" % (statistics.median(estimates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In view of the heterogeneity of the estimates, the median is a better estimate. Since the extreme values did not represent reality accurately, the average could not represent it either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
